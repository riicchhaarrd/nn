<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>Enhanced Neural Network Curve Approximation with C Export</title>
  <style>
    /* Container for side-by-side layout */
    #container {
      display: flex;
      justify-content: center;
      align-items: flex-start;
      gap: 20px;
      margin: 20px;
    }

    /* Left panel for the canvas */
    #left-panel {
      /* The canvas retains its 600px width and 400px height */
    }

    /* Right panel for stats and export function */
    #right-panel {
      display: flex;
      flex-direction: column;
      gap: 20px;
      width: 300px;
    }

    #right-panel2 {
      display: flex;
      flex-direction: column;
      gap: 20px;
    }

    /* Styling for stats and export containers */
    #stats,
    #export-container {
      width: 100%;
      font-family: monospace;
      white-space: pre-wrap;
      background: #f9f9f9;
      padding: 10px;
      border: 1px solid #ddd;
      box-sizing: border-box;
    }

    #export-container2 {
      /* width: 100%; */
      font-family: monospace;
      /* white-space: pre-wrap; */
      background: #f9f9f9;
      padding: 10px;
      border: 1px solid #ddd;
      box-sizing: border-box;
    }

    #export {
      /* width: 100%; */
      height: 430px;
      width: 370px;
      font-family: monospace;
      box-sizing: border-box;
    }

    canvas {
      border: 1px solid #333;
      display: block;
    }

    /* Styling for control panel */
    #control-panel {
      margin-top: 10px;
      padding: 10px;
      background: #f0f0f0;
      border: 1px solid #ddd;
    }

    #network-controls {
      display: grid;
      grid-template-columns: auto auto;
      gap: 8px;
      align-items: center;
      margin-bottom: 10px;
    }

    #function-controls {
      display: grid;
      grid-template-columns: auto auto;
      gap: 8px;
      align-items: center;
      margin-top: 10px;
      padding-top: 10px;
      border-top: 1px solid #ddd;
    }

    select,
    input,
    label {
      font-family: sans-serif;
    }

    input[type="number"] {
      width: 60px;
    }

    button {
      margin-top: 10px;
      padding: 5px 10px;
      background: #4CAF50;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }

    button:hover {
      background: #45a049;
    }
  </style>
</head>

<body>
  <div id="container">
    <div id="left-panel">
      <canvas id="canvas" width="600" height="400"></canvas>
      <div id="control-panel">
        <div id="network-controls">
          <label for="hidden-size">Hidden Neurons:</label>
          <input type="number" id="hidden-size" min="1" max="50" value="10">

          <label for="num-layers">Hidden Layers:</label>
          <input type="number" id="num-layers" min="1" max="10" value="1">

          <label for="learning-rate">Learning Rate:</label>
          <input type="number" id="learning-rate" min="0.0001" max="1" step="0.001" value="0.001">

          <label for="batch-size">Training Steps/Frame:</label>
          <input type="number" id="batch-size" min="1" max="1000" value="10000">

          <label for="activation-function">Activation Function:</label>
          <select id="activation-function">
            <option value="tanh">Tanh</option>
            <option value="sigmoid">Sigmoid</option>
            <option value="relu">ReLU</option>
            <option value="leakyRelu">Leaky ReLU</option>
            <option value="swish">Swish</option>
            <option value="smoothstep">Smoothstep</option>
            <option value="cos">Cosine</option>
          </select>
        </div>

        <div id="function-controls">
          <label for="target-function">Target Function:</label>
          <select id="target-function">
            <option value="sine">Sine</option>
            <option value="polynomial">Polynomial</option>
            <option value="square">Square Wave</option>
            <option value="step">Step Function</option>
            <option value="custom">Custom</option>
          </select>

          <label for="custom-function" id="custom-function-label" style="display:none;">Custom Function:</label>
          <input type="text" id="custom-function" value="Math.sin(x)" style="display:none;">
        </div>

        <button id="reset-network">Reset Network</button>
        <button id="pause-training">Pause Training</button>
      </div>
    </div>
    <div id="right-panel">
      <div id="stats"></div>
    </div>
    <div id="right-panel2">
      <div id="export-container2">
        <strong>Exported C Function:</strong>
        <div>
          <textarea id="export" readonly></textarea>
        </div>
      </div>
    </div>
  </div>
  <script>
    // Helper functions for smoothstep
    function mix(a, b, weightb) {
      return (1 - weightb) * a + (weightb) * b;
    }
    function squared(x) {
      return x * x;
    }
    function flip(x) {
      return 1 - x;
    }
    function smoothstart(t) {
      return squared(t);
    }
    function smoothstop(t) {
      return flip(squared(flip(t)));
    }
    function smoothstepFunc(x) {
      let t = (x + 4) / 8;
      t = Math.max(0, Math.min(1, t));
      let result = mix(smoothstart(t), smoothstop(t), t);
      return result * 2 - 1;
    }
    function smoothstepPrime(x) {
      let t = (x + 4) / 8;
      if (t <= 0 || t >= 1) return 0;
      let dtResult = 6 * t * (1 - t);
      return dtResult * (1 / 8) * 2;
    }

    // Neural Network with multiple hidden layers
    class NeuralNetwork {
      constructor(inputSize, hiddenSize, numHiddenLayers, outputSize, learningRate) {
        this.inputSize = inputSize;
        this.hiddenSize = hiddenSize;
        this.numHiddenLayers = numHiddenLayers;
        this.outputSize = outputSize;
        this.learningRate = learningRate;
        this.activationFunction = "tanh"; // default activation
        this.initializeWeights();
      }

      initializeWeights() {
        this.weights = [];
        this.biases = [];
        let inputDim = this.inputSize;
        for (let l = 0; l < this.numHiddenLayers; l++) {
          let layerWeights = [];
          let layerBiases = [];
          for (let i = 0; i < this.hiddenSize; i++) {
            let neuronWeights = [];
            for (let j = 0; j < inputDim; j++) {
              neuronWeights.push(Math.random() * 2 - 1);
            }
            layerWeights.push(neuronWeights);
            layerBiases.push(Math.random() * 2 - 1);
          }
          this.weights.push(layerWeights);
          this.biases.push(layerBiases);
          inputDim = this.hiddenSize;
        }
        this.outputWeights = [];
        for (let i = 0; i < this.hiddenSize; i++) {
          this.outputWeights.push(Math.random() * 2 - 1);
        }
        this.outputBias = Math.random() * 2 - 1;
      }

      setActivationFunction(funcName) {
        this.activationFunction = funcName;
      }

      setLearningRate(rate) {
        this.learningRate = rate;
      }

      setHiddenSize(size) {
        this.hiddenSize = size;
        this.initializeWeights();
      }

      setNumHiddenLayers(numLayers) {
        this.numHiddenLayers = numLayers;
        this.initializeWeights();
      }

      activate(x) {
        switch (this.activationFunction) {
          case "sigmoid":
            return 1 / (1 + Math.exp(-x));
          case "relu":
            return Math.max(0, x);
          case "leakyRelu":
            return x > 0 ? x : 0.01 * x;
          case "swish":
            return x * (1 / (1 + Math.exp(-x)));
          case "smoothstep":
            return smoothstepFunc(x);
          case "cos":
            return Math.cos(x);
          case "tanh":
          default:
            return Math.tanh(x);
        }
      }

      activatePrime(x) {
        switch (this.activationFunction) {
          case "sigmoid":
            let sig = 1 / (1 + Math.exp(-x));
            return sig * (1 - sig);
          case "relu":
            return x > 0 ? 1 : 0;
          case "leakyRelu":
            return x > 0 ? 1 : 0.01;
          case "swish":
            let sigm = 1 / (1 + Math.exp(-x));
            return sigm + x * sigm * (1 - sigm);
          case "smoothstep":
            return smoothstepPrime(x);
          case "cos":
            return -Math.sin(x);
          case "tanh":
          default:
            return 1 - Math.tanh(x) * Math.tanh(x);
        }
      }

      forward(x) {
        let input = [x];
        this.a = [];
        this.h = [];
        for (let l = 0; l < this.numHiddenLayers; l++) {
          let aLayer = [];
          let hLayer = [];
          for (let i = 0; i < this.hiddenSize; i++) {
            let sum = 0;
            for (let j = 0; j < input.length; j++) {
              sum += input[j] * this.weights[l][i][j];
            }
            sum += this.biases[l][i];
            aLayer.push(sum);
            hLayer.push(this.activate(sum));
          }
          this.a.push(aLayer);
          this.h.push(hLayer);
          input = hLayer;
        }
        let output = this.outputBias;
        for (let i = 0; i < input.length; i++) {
          output += input[i] * this.outputWeights[i];
        }
        return output;
      }

      train(x, target) {
        let output = this.forward(x);
        let error = output - target;

        // Update output layer weights and bias
        for (let i = 0; i < this.hiddenSize; i++) {
          let grad = error * this.h[this.numHiddenLayers - 1][i];
          this.outputWeights[i] -= this.learningRate * grad;
        }
        this.outputBias -= this.learningRate * error;

        // Backpropagation through hidden layers
        let deltas = [];
        let lastLayer = this.numHiddenLayers - 1;
        let delta = [];
        for (let i = 0; i < this.hiddenSize; i++) {
          delta.push(error * this.outputWeights[i] * this.activatePrime(this.a[lastLayer][i]));
        }
        deltas[lastLayer] = delta;

        for (let l = this.numHiddenLayers - 2; l >= 0; l--) {
          let deltaNext = deltas[l + 1];
          let deltaCurrent = [];
          for (let i = 0; i < this.hiddenSize; i++) {
            let sum = 0;
            for (let k = 0; k < this.hiddenSize; k++) {
              sum += deltaNext[k] * this.weights[l + 1][k][i];
            }
            deltaCurrent.push(sum * this.activatePrime(this.a[l][i]));
          }
          deltas[l] = deltaCurrent;
        }

        for (let l = 0; l < this.numHiddenLayers; l++) {
          let layerInput = (l === 0) ? [x] : this.h[l - 1];
          for (let i = 0; i < this.hiddenSize; i++) {
            for (let j = 0; j < layerInput.length; j++) {
              this.weights[l][i][j] -= this.learningRate * deltas[l][i] * layerInput[j];
            }
            this.biases[l][i] -= this.learningRate * deltas[l][i];
          }
        }
      }
    }

    // Set up canvas and coordinate transforms
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const width = canvas.width;
    const height = canvas.height;
    const xMin = -Math.PI;
    const xMax = Math.PI;
    const yMin = -1.5;
    const yMax = 1.5;
    function transformX(x) {
      return (x - xMin) / (xMax - xMin) * width;
    }
    function transformY(y) {
      return height - ((y - yMin) / (yMax - yMin) * height);
    }

    // Get DOM elements for controls
    const hiddenSizeInput = document.getElementById("hidden-size");
    const numLayersInput = document.getElementById("num-layers");
    const learningRateInput = document.getElementById("learning-rate");
    const batchSizeInput = document.getElementById("batch-size");
    const activationSelect = document.getElementById("activation-function");
    const targetFunctionSelect = document.getElementById("target-function");
    const customFunctionInput = document.getElementById("custom-function");
    const customFunctionLabel = document.getElementById("custom-function-label");
    const resetButton = document.getElementById("reset-network");
    const pauseButton = document.getElementById("pause-training");

    // Create the neural network with multi-layer support
    let nn = new NeuralNetwork(1, parseInt(hiddenSizeInput.value), parseInt(numLayersInput.value), 1, parseFloat(learningRateInput.value));
    let isTraining = true;
    let batchSize = parseInt(batchSizeInput.value);
    let currentTargetFunction = "sine";

    // Target function selection
    function targetFunction(x) {
      switch (currentTargetFunction) {
        case "polynomial":
          return x * x * (1 - x);
        case "square":
          return Math.sin(x) > 0 ? 1 : -1;
        case "step":
          return x > 0 ? 1 : -1;
        case "custom":
          try {
            return new Function('x', 'return ' + customFunctionInput.value)(x);
          } catch (e) {
            console.error("Error in custom function:", e);
            return Math.sin(x);
          }
        case "sine":
        default:
          return Math.sin(x);
      }
    }

    // Perform one training step using a random sample
    function trainStep() {
      if (!isTraining) return;
      let x = Math.random() * (xMax - xMin) + xMin;
      let y = targetFunction(x);
      nn.train(x, y);
    }

    // Draw the target function and network approximation
    function draw() {
      ctx.clearRect(0, 0, width, height);
      ctx.strokeStyle = "black";
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(0, transformY(0));
      ctx.lineTo(width, transformY(0));
      ctx.moveTo(transformX(0), 0);
      ctx.lineTo(transformX(0), height);
      ctx.stroke();

      ctx.strokeStyle = "blue";
      ctx.lineWidth = 2;
      ctx.beginPath();
      let firstPoint = true;
      for (let i = 0; i <= width; i++) {
        let xVal = xMin + (i / width) * (xMax - xMin);
        let yVal = targetFunction(xVal);
        let canvasX = transformX(xVal);
        let canvasY = transformY(yVal);
        if (firstPoint) { ctx.moveTo(canvasX, canvasY); firstPoint = false; }
        else { ctx.lineTo(canvasX, canvasY); }
      }
      ctx.stroke();

      ctx.strokeStyle = "red";
      ctx.lineWidth = 2;
      ctx.beginPath();
      firstPoint = true;
      for (let i = 0; i <= width; i++) {
        let xVal = xMin + (i / width) * (xMax - xMin);
        let yVal = nn.forward(xVal);
        let canvasX = transformX(xVal);
        let canvasY = transformY(yVal);
        if (firstPoint) { ctx.moveTo(canvasX, canvasY); firstPoint = false; }
        else { ctx.lineTo(canvasX, canvasY); }
      }
      ctx.stroke();

      ctx.font = "12px Arial";
      ctx.fillStyle = "blue";
      ctx.fillText("Target Function", 10, 20);
      ctx.fillStyle = "red";
      ctx.fillText("Neural Network Output", 10, 40);
    }

    // Update the stats display
    function updateStats() {
      const statsDiv = document.getElementById("stats");
      let statsText = "Network Configuration:\n";
      statsText += `Hidden Neurons: ${nn.hiddenSize}\n`;
      statsText += `Hidden Layers: ${nn.numHiddenLayers}\n`;
      statsText += `Learning Rate: ${nn.learningRate}\n`;
      statsText += `Activation: ${nn.activationFunction}\n`;
      statsText += `Target Function: ${currentTargetFunction}\n\n`;

      for (let l = 0; l < nn.numHiddenLayers; l++) {
        statsText += `Layer ${l} Weights:\n` +
          nn.weights[l].map((neuron, i) => `  Neuron ${i}: ${neuron.map(w => w.toFixed(6)).join(", ")}`).join("\n") + "\n\n";
        statsText += `Layer ${l} Biases:\n` +
          nn.biases[l].map((b, i) => `  Neuron ${i}: ${b.toFixed(6)}`).join("\n") + "\n\n";
      }
      statsText += "Output Weights:\n" +
        nn.outputWeights.map((w, i) => `  Neuron ${i}: ${w.toFixed(6)}`).join("\n") + "\n\n";
      statsText += "Output Bias: " + nn.outputBias.toFixed(6);
      statsDiv.textContent = statsText;
    }

    // Generate and update the exported C function
    function updateExport() {
      const exportArea = document.getElementById("export");
      let code = "";
      let scalar_type = "float";
      let activationFuncName = "";
      switch (nn.activationFunction) {
        case "sigmoid":
          code += "// Helper sigmoid function\n";
          code += scalar_type + " sigmoid(" + scalar_type + " x) { return 1.0 / (1.0 + exp(-x)); }\n\n";
          activationFuncName = "sigmoid";
          break;
        case "relu":
          code += "// Helper ReLU function\n";
          code += scalar_type + " relu(" + scalar_type + " x) { return x > 0 ? x : 0; }\n\n";
          activationFuncName = "relu";
          break;
        case "leakyRelu":
          code += "// Helper Leaky ReLU function\n";
          code += scalar_type + " leaky_relu(" + scalar_type + " x) { return x > 0 ? x : 0.01 * x; }\n\n";
          activationFuncName = "leaky_relu";
          break;
        case "swish":
          code += "// Helper Swish function\n";
          code += scalar_type + " swish(" + scalar_type + " x) { return x * (1.0 / (1.0 + exp(-x))); }\n\n";
          activationFuncName = "swish";
          break;
        case "smoothstep":
          code += "// Helper functions for smoothstep\n";
          code += scalar_type + " mix(" + scalar_type + " a, " + scalar_type + " b, " + scalar_type + " weightb) { return (1.0 - weightb) * a + weightb * b; }\n";
          code += scalar_type + " squared(" + scalar_type + " x) { return x * x; }\n";
          code += scalar_type + " flip(" + scalar_type + " x) { return 1.0 - x; }\n";
          code += scalar_type + " smoothstart(" + scalar_type + " t) { return squared(t); }\n";
          code += scalar_type + " smoothstop(" + scalar_type + " t) { return flip(squared(flip(t))); }\n";
          code += scalar_type + " smoothstep_(" + scalar_type + " x) {\n";
          code += "    " + scalar_type + " t = (x + 4.0) / 8.0;\n";
          code += "    t = t < 0.0 ? 0.0 : (t > 1.0 ? 1.0 : t);\n";
          code += "    " + scalar_type + " result = mix(smoothstart(t), smoothstop(t), t);\n";
          code += "    return result * 2.0 - 1.0;\n";
          code += "}\n\n";
          activationFuncName = "smoothstep_";
          break;
        case "cos":
          activationFuncName = "cos";
          break;
        case "tanh":
        default:
          activationFuncName = "tanh";
      }

      code += scalar_type + " f(" + scalar_type + " x) {\n";
      for (let l = 0; l < nn.numHiddenLayers; l++) {
        for (let i = 0; i < nn.hiddenSize; i++) {
          if (l === 0) {
            code += "    " + scalar_type + " a0_" + i + " = " + activationFuncName + "(x * " + nn.weights[0][i][0].toFixed(6) + " + " + nn.biases[0][i].toFixed(6) + ");\n";
          } else {
            let sumParts = "";
            for (let j = 0; j < nn.hiddenSize; j++) {
              sumParts += "a" + (l - 1) + "_" + j + " * " + nn.weights[l][i][j].toFixed(6) + " + ";
            }
            sumParts = sumParts.slice(0, -3);
            code += "    " + scalar_type + " a" + l + "_" + i + " = " + activationFuncName + "(" + sumParts + " + " + nn.biases[l][i].toFixed(6) + ");\n";
          }
        }
      }
      let lastLayer = nn.numHiddenLayers - 1;
      code += "    " + scalar_type + " y = " + nn.outputBias.toFixed(6) + ";\n";
      for (let i = 0; i < nn.hiddenSize; i++) {
        code += "    y += a" + lastLayer + "_" + i + " * " + nn.outputWeights[i].toFixed(6) + ";\n";
      }
      code += "    return y;\n";
      code += "}\n";

      exportArea.value = code;
    }

    activationSelect.addEventListener("change", function () {
      nn.setActivationFunction(this.value);
    });

    targetFunctionSelect.addEventListener("change", function () {
      currentTargetFunction = this.value;
      if (this.value === "custom") {
        customFunctionInput.style.display = "inline-block";
        customFunctionLabel.style.display = "inline-block";
      } else {
        customFunctionInput.style.display = "none";
        customFunctionLabel.style.display = "none";
      }
    });

    customFunctionInput.addEventListener("change", function () {
      try {
        let testFunc = new Function('x', 'return ' + this.value);
        testFunc(0);
      } catch (e) {
        alert("Invalid function expression. Please check your syntax.");
        this.value = "Math.sin(x)";
      }
    });

    hiddenSizeInput.addEventListener("change", function () {
      const size = parseInt(this.value);
      if (size > 0) {
        nn.setHiddenSize(size);
      } else {
        this.value = "1";
        nn.setHiddenSize(1);
      }
    });

    numLayersInput.addEventListener("change", function () {
      const numLayers = parseInt(this.value);
      if (numLayers > 0) {
        nn.setNumHiddenLayers(numLayers);
      } else {
        this.value = "1";
        nn.setNumHiddenLayers(1);
      }
    });

    learningRateInput.addEventListener("change", function () {
      const rate = parseFloat(this.value);
      if (rate > 0) {
        nn.setLearningRate(rate);
      } else {
        this.value = "0.01";
        nn.setLearningRate(0.01);
      }
    });

    batchSizeInput.addEventListener("change", function () {
      const size = parseInt(this.value);
      if (size > 0) {
        batchSize = size;
      } else {
        this.value = "100";
        batchSize = 100;
      }
    });

    resetButton.addEventListener("click", function () {
      nn.initializeWeights();
    });

    pauseButton.addEventListener("click", function () {
      isTraining = !isTraining;
      this.textContent = isTraining ? "Pause Training" : "Resume Training";
    });

    function animate() {
      for (let i = 0; i < batchSize; i++) {
        trainStep();
      }
      draw();
      updateStats();
      updateExport();
      requestAnimationFrame(animate);
    }

    animate();
  </script>
</body>

</html>