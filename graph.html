<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Enhanced Neural Network Curve Approximation with C Export</title>
    <style>
        /* Container for side-by-side layout */
        #container {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            gap: 20px;
            margin: 20px;
        }

        /* Left panel for the canvas */
        #left-panel {
            /* The canvas retains its 600px width and 400px height */
        }

        /* Right panel for stats and export function */
        #right-panel {
            display: flex;
            flex-direction: column;
            gap: 20px;
            width: 300px;
        }
        #right-panel2 {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        /* Styling for stats and export containers */
        #stats,
        #export-container {
            width: 100%;
            font-family: monospace;
            white-space: pre-wrap;
            background: #f9f9f9;
            padding: 10px;
            border: 1px solid #ddd;
            box-sizing: border-box;
        }
        #export-container2 {
            /* width: 100%; */
            font-family: monospace;
            /* white-space: pre-wrap; */
            background: #f9f9f9;
            padding: 10px;
            border: 1px solid #ddd;
            box-sizing: border-box;
        }

        #export {
            /* width: 100%; */
            height: 430px;
            width:370px;
            font-family: monospace;
            box-sizing: border-box;
        }

        canvas {
            border: 1px solid #333;
            display: block;
        }

        /* Styling for control panel */
        #control-panel {
            margin-top: 10px;
            padding: 10px;
            background: #f0f0f0;
            border: 1px solid #ddd;
        }

        #network-controls {
            display: grid;
            grid-template-columns: auto auto;
            gap: 8px;
            align-items: center;
            margin-bottom: 10px;
        }

        #function-controls {
            display: grid;
            grid-template-columns: auto auto;
            gap: 8px;
            align-items: center;
            margin-top: 10px;
            padding-top: 10px;
            border-top: 1px solid #ddd;
        }

        select,
        input,
        label {
            font-family: sans-serif;
        }

        input[type="number"] {
            width: 60px;
        }

        button {
            margin-top: 10px;
            padding: 5px 10px;
            background: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }

        button:hover {
            background: #45a049;
        }
    </style>
</head>

<body>
    <div id="container">
        <div id="left-panel">
            <canvas id="canvas" width="600" height="400"></canvas>
            <div id="control-panel">
                <div id="network-controls">
                    <label for="hidden-size">Hidden Neurons:</label>
                    <input type="number" id="hidden-size" min="1" max="50" value="10">

                    <label for="learning-rate">Learning Rate:</label>
                    <input type="number" id="learning-rate" min="0.0001" max="1" step="0.001" value="0.001">
                    <!-- <input type="number" id="learning-rate" min="0.0001" max="1" step="0.001" value="0.01"> -->

                    <label for="batch-size">Training Steps/Frame:</label>
                    <input type="number" id="batch-size" min="1" max="1000" value="10000">
                    <!-- <input type="number" id="batch-size" min="1" max="1000" value="100"> -->

                    <label for="activation-function">Activation Function:</label>
                    <select id="activation-function">
                        <option value="tanh">Tanh</option>
                        <option value="sigmoid">Sigmoid</option>
                        <option value="relu">ReLU</option>
                        <option value="leakyRelu">Leaky ReLU</option>
                        <option value="swish">Swish</option>
                        <option value="smoothstep">Smoothstep</option>
                        <option value="cos">Cosine</option>
                    </select>
                </div>

                <div id="function-controls">
                    <label for="target-function">Target Function:</label>
                    <select id="target-function">
                        <option value="sine">Sine</option>
                        <option value="polynomial">Polynomial</option>
                        <option value="square">Square Wave</option>
                        <option value="step">Step Function</option>
                        <option value="custom">Custom</option>
                    </select>

                    <label for="custom-function" id="custom-function-label" style="display:none;">Custom Function:</label>
                    <input type="text" id="custom-function" value="Math.sin(x)" style="display:none;">
                </div>

                <button id="reset-network">Reset Network</button>
                <button id="pause-training">Pause Training</button>
            </div>
        </div>
        <div id="right-panel">
            <div id="stats"></div>
        </div>
        <div id="right-panel2">
            <div id="export-container2">
                <strong>Exported C Function:</strong>
                <div>
                    
                <textarea id="export" readonly></textarea>
            </div>
            </div>
        </div>
    </div>
    <script>
        // Helper functions for smoothstep
        function mix(a, b, weightb) {
            return (1 - weightb) * a + (weightb) * b;
        }

        function squared(x) {
            return x * x;
        }

        function flip(x) {
            return 1 - x;
        }

        function smoothstart(t) {
            // Equivalent to t^2
            return squared(t);
        }

        function smoothstop(t) {
            // Equivalent to 1-(1-t)^2
            return flip(squared(flip(t)));
        }

        function smoothstepFunc(x) {
            // Normalize input to 0-1 range for smoothstep
            // We'll use a range of -4 to 4 for the normalization
            let t = (x + 4) / 8;
            t = Math.max(0, Math.min(1, t)); // Clamp to [0,1]

            // Apply smoothstep which is a mix of smoothstart and smoothstop
            let result = mix(smoothstart(t), smoothstop(t), t);

            // Scale result to be in similar range as tanh (-1 to 1)
            return result * 2 - 1;
        }

        // Derivative of smoothstep function
        function smoothstepPrime(x) {
            // Normalize input to 0-1 range for smoothstep
            let t = (x + 4) / 8;
            if (t <= 0 || t >= 1) return 0; // Derivative is 0 outside [0,1]

            // Derivative of smoothstep in t-space
            let dtResult = 6 * t * (1 - t);

            // Chain rule: multiply by derivative of normalization (1/8)
            return dtResult * (1 / 8) * 2; // * 2 for the scaling we applied
        }

        // Neural Network with one hidden layer
        class NeuralNetwork {
            constructor(inputSize, hiddenSize, outputSize, learningRate) {
                this.inputSize = inputSize;
                this.hiddenSize = hiddenSize;
                this.outputSize = outputSize;
                this.learningRate = learningRate;
                this.activationFunction = "tanh"; // default activation function

                this.initializeWeights();
            }

            initializeWeights() {
                // Initialize weights and biases randomly between -1 and 1
                this.weights1 = new Array(this.hiddenSize).fill(0).map(() => Math.random() * 2 - 1);
                this.bias1 = new Array(this.hiddenSize).fill(0).map(() => Math.random() * 2 - 1);
                this.weights2 = new Array(this.hiddenSize).fill(0).map(() => Math.random() * 2 - 1);
                this.bias2 = Math.random() * 2 - 1;
            }

            // Set the activation function
            setActivationFunction(funcName) {
                this.activationFunction = funcName;
            }

            // Update learning rate
            setLearningRate(rate) {
                this.learningRate = rate;
            }

            // Update hidden layer size
            setHiddenSize(size) {
                this.hiddenSize = size;
                this.initializeWeights();
            }

            // Activation functions
            activate(x) {
                switch (this.activationFunction) {
                    case "sigmoid":
                        return 1 / (1 + Math.exp(-x));
                    case "relu":
                        return Math.max(0, x);
                    case "leakyRelu":
                        return x > 0 ? x : 0.01 * x;
                    case "swish":
                        return x * (1 / (1 + Math.exp(-x)));
                    case "smoothstep":
                        return smoothstepFunc(x);
                    case "cos":
                        return Math.cos(x);
                    case "tanh":
                    default:
                        return Math.tanh(x);
                }
            }

            // Derivatives of activation functions
            activatePrime(x) {
                switch (this.activationFunction) {
                    case "sigmoid":
                        let sig = 1 / (1 + Math.exp(-x));
                        return sig * (1 - sig);
                    case "relu":
                        return x > 0 ? 1 : 0;
                    case "leakyRelu":
                        return x > 0 ? 1 : 0.01;
                    case "swish":
                        let sigm = 1 / (1 + Math.exp(-x));
                        return sigm + x * sigm * (1 - sigm);
                    case "smoothstep":
                        return smoothstepPrime(x);
                    case "cos":
                        return -Math.sin(x);
                    case "tanh":
                    default:
                        return 1 - Math.tanh(x) * Math.tanh(x);
                }
            }

            // Forward pass: Given input x, compute the network output.
            forward(x) {
                this.a = []; // Pre-activation values for hidden neurons
                this.h = []; // Post-activation values for hidden neurons
                for (let i = 0; i < this.hiddenSize; i++) {
                    let a = x * this.weights1[i] + this.bias1[i];
                    this.a[i] = a;
                    this.h[i] = this.activate(a);
                }
                // Output layer: linear combination of hidden outputs plus bias
                let output = this.bias2;
                for (let i = 0; i < this.hiddenSize; i++) {
                    output += this.weights2[i] * this.h[i];
                }
                return output;
            }

            // Single training step using SGD for one sample (x, target)
            train(x, target) {
                // Forward pass
                let output = this.forward(x);
                let error = output - target;  // error (for squared error loss)

                // Backpropagate: update output layer weights and bias
                for (let i = 0; i < this.hiddenSize; i++) {
                    let gradW2 = error * this.h[i];
                    this.weights2[i] -= this.learningRate * gradW2;
                }
                this.bias2 -= this.learningRate * error;

                // Backpropagate into the hidden layer
                for (let i = 0; i < this.hiddenSize; i++) {
                    let deltaHidden = error * this.weights2[i] * this.activatePrime(this.a[i]);
                    this.weights1[i] -= this.learningRate * deltaHidden * x;
                    this.bias1[i] -= this.learningRate * deltaHidden;
                }
            }
        }

        // Set up canvas and coordinate transforms
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const width = canvas.width;
        const height = canvas.height;

        // Define the domain for x and range for y.
        // Here, we use x ∈ [–π, π] and y ∈ [–1.5, 1.5]
        const xMin = -Math.PI;
        const xMax = Math.PI;
        const yMin = -1.5;
        const yMax = 1.5;

        function transformX(x) {
            return (x - xMin) / (xMax - xMin) * width;
        }

        function transformY(y) {
            // Flip y so that higher y-values appear at the top of the canvas
            return height - ((y - yMin) / (yMax - yMin) * height);
        }

        // Get DOM elements for controls
        const hiddenSizeInput = document.getElementById("hidden-size");
        const learningRateInput = document.getElementById("learning-rate");
        const batchSizeInput = document.getElementById("batch-size");
        const activationSelect = document.getElementById("activation-function");
        const targetFunctionSelect = document.getElementById("target-function");
        const customFunctionInput = document.getElementById("custom-function");
        const customFunctionLabel = document.getElementById("custom-function-label");
        const resetButton = document.getElementById("reset-network");
        const pauseButton = document.getElementById("pause-training");

        // Create the neural network (1 input, 10 hidden neurons, 1 output) with learning rate 0.01
        let nn = new NeuralNetwork(1, parseInt(hiddenSizeInput.value), 1, parseFloat(learningRateInput.value));
        let isTraining = true;
        let batchSize = parseInt(batchSizeInput.value);
        let currentTargetFunction = "sine";

        // Target function selection
        function targetFunction(x) {
            switch (currentTargetFunction) {
                case "polynomial":
                    return x * x * (1 - x);
                case "square":
                    return Math.sin(x) > 0 ? 1 : -1;
                case "step":
                    return x > 0 ? 1 : -1;
                case "custom":
                    try {
                        // Function constructor to evaluate custom function expressions
                        return new Function('x', 'return ' + customFunctionInput.value)(x);
                    } catch (e) {
                        console.error("Error in custom function:", e);
                        return Math.sin(x); // Fallback to sine
                    }
                case "sine":
                default:
                    return Math.sin(x);
            }
        }

        // Perform one training step using a random sample from the domain
        function trainStep() {
            if (!isTraining) return;
            
            let x = Math.random() * (xMax - xMin) + xMin;
            let y = targetFunction(x);
            nn.train(x, y);
        }

        // Draw the true target function and the neural network's approximation
        function draw() {
            ctx.clearRect(0, 0, width, height);

            // Draw axes
            ctx.strokeStyle = "black";
            ctx.lineWidth = 1;
            ctx.beginPath();
            // X-axis
            ctx.moveTo(0, transformY(0));
            ctx.lineTo(width, transformY(0));
            // Y-axis
            ctx.moveTo(transformX(0), 0);
            ctx.lineTo(transformX(0), height);
            ctx.stroke();

            // Draw the true target curve (blue)
            ctx.strokeStyle = "blue";
            ctx.lineWidth = 2;
            ctx.beginPath();
            let firstPoint = true;
            for (let i = 0; i <= width; i++) {
                let xVal = xMin + (i / width) * (xMax - xMin);
                let yVal = targetFunction(xVal);
                let canvasX = transformX(xVal);
                let canvasY = transformY(yVal);
                if (firstPoint) {
                    ctx.moveTo(canvasX, canvasY);
                    firstPoint = false;
                } else {
                    ctx.lineTo(canvasX, canvasY);
                }
            }
            ctx.stroke();

            // Draw the neural network's approximation (red)
            ctx.strokeStyle = "red";
            ctx.lineWidth = 2;
            ctx.beginPath();
            firstPoint = true;
            for (let i = 0; i <= width; i++) {
                let xVal = xMin + (i / width) * (xMax - xMin);
                let yVal = nn.forward(xVal);
                let canvasX = transformX(xVal);
                let canvasY = transformY(yVal);
                if (firstPoint) {
                    ctx.moveTo(canvasX, canvasY);
                    firstPoint = false;
                } else {
                    ctx.lineTo(canvasX, canvasY);
                }
            }
            ctx.stroke();

            // Add legend
            ctx.font = "12px Arial";
            ctx.fillStyle = "blue";
            ctx.fillText("Target Function", 10, 20);
            ctx.fillStyle = "red";
            ctx.fillText("Neural Network Output", 10, 40);
        }

        // Update the stats display with current weights and biases
        function updateStats() {
            const statsDiv = document.getElementById("stats");
            let statsText = "Network Configuration:\n";
            statsText += `Hidden Neurons: ${nn.hiddenSize}\n`;
            statsText += `Learning Rate: ${nn.learningRate}\n`;
            statsText += `Activation: ${nn.activationFunction}\n`;
            statsText += `Target Function: ${currentTargetFunction}\n\n`;
            
            statsText += "Weights1 (input -> hidden):\n" +
                nn.weights1.map((w, i) => `  Neuron ${i}: ${w.toFixed(6)}`).join("\n") + "\n\n";
            statsText += "Bias1 (hidden):\n" +
                nn.bias1.map((b, i) => `  Neuron ${i}: ${b.toFixed(6)}`).join("\n") + "\n\n";
            statsText += "Weights2 (hidden -> output):\n" +
                nn.weights2.map((w, i) => `  Neuron ${i}: ${w.toFixed(6)}`).join("\n") + "\n\n";
            statsText += "Bias2 (output): " + nn.bias2.toFixed(6);
            statsDiv.textContent = statsText;
        }

        // Generate and update the export textarea with a C function
        function updateExport() {
            const exportArea = document.getElementById("export");
            let code = "";
            let scalar_type = "float";
            // Add appropriate activation function implementation based on current selection
            switch (nn.activationFunction) {
                case "sigmoid":
                    code += "// Helper sigmoid function\n";
                    code += `${scalar_type} sigmoid(${scalar_type} x) { return 1.0 / (1.0 + exp(-x)); }\n\n`;
                    break;
                case "relu":
                    code += "// Helper ReLU function\n";
                    code += `${scalar_type} relu(${scalar_type} x) { return x > 0 ? x : 0; }\n\n`;
                    break;
                case "leakyRelu":
                    code += "// Helper Leaky ReLU function\n";
                    code += `${scalar_type} leaky_relu(${scalar_type} x) { return x > 0 ? x : 0.01 * x; }\n\n`;
                    break;
                case "swish":
                    code += "// Helper Swish function\n";
                    code += `${scalar_type} swish(${scalar_type} x) { return x * (1.0 / (1.0 + exp(-x))); }\n\n`;
                    break;
                case "smoothstep":
                    code += `// Helper functions for smoothstep\n`;
                    code += `${scalar_type} mix(${scalar_type} a, ${scalar_type} b, ${scalar_type} weightb) { return (1.0 - weightb) * a + weightb * b; }\n`;
                    code += `${scalar_type} squared(${scalar_type} x) { return x * x; }\n`;
                    code += `${scalar_type} flip(${scalar_type} x) { return 1.0 - x; }\n`;
                    code += `${scalar_type} smoothstart(${scalar_type} t) { return squared(t); }\n`;
                    code += `${scalar_type} smoothstop(${scalar_type} t) { return flip(squared(flip(t))); }\n`;
                    code += `${scalar_type} smoothstep_(${scalar_type} x) {\n`;
                    code += `    // Normalize to 0-1 range\n`;
                    code += `    ${scalar_type} t = (x + 4.0) / 8.0;\n`;
                    code += `    t = t < 0.0 ? 0.0 : (t > 1.0 ? 1.0 : t);\n`;
                    code += `    // Apply smoothstep\n`;
                    code += `    ${scalar_type} result = mix(smoothstart(t), smoothstop(t), t);\n`;
                    code += `    // Scale to similar range as tanh\n`;
                    code += `    return result * 2.0 - 1.0;\n`;
                    code += `}\n\n`;
                    break;
                // tanh is built into standard C math library, so no need to define it
            }

            code += `${scalar_type} f(${scalar_type} x) {\n`;
            // Compute each hidden neuron output using the selected activation function
            for (let i = 0; i < nn.hiddenSize; i++) {
                let activationFunc = "";
                switch (nn.activationFunction) {
                    case "sigmoid":
                        activationFunc = "sigmoid";
                        break;
                    case "relu":
                        activationFunc = "relu";
                        break;
                    case "leakyRelu":
                        activationFunc = "leaky_relu";
                        break;
                    case "swish":
                        activationFunc = "swish";
                        break;
                    case "smoothstep":
                        activationFunc = "smoothstep_";
                        break;
                    case "cos":
                        activationFunc = "cos";
                        break;
                    case "tanh":
                    default:
                        activationFunc = "tanh";
                }
                code += `    ${scalar_type} a${i} = ${activationFunc}(x * ${nn.weights1[i].toFixed(6)} + ${nn.bias1[i].toFixed(6)});\n`;
            }

            code += `    ${scalar_type} y = ` + nn.bias2.toFixed(6) + `;\n`;
            for (let i = 0; i < nn.hiddenSize; i++) {
                code += "    y += " + nn.weights2[i].toFixed(6) + " * a" + i + ";\n";
            }
            code += "    return y;\n";
            code += "}\n";
            exportArea.value = code;
        }

        // Set up event listeners for controls
        activationSelect.addEventListener("change", function () {
            nn.setActivationFunction(this.value);
        });

        targetFunctionSelect.addEventListener("change", function () {
            currentTargetFunction = this.value;
            if (this.value === "custom") {
                customFunctionInput.style.display = "inline-block";
                customFunctionLabel.style.display = "inline-block";
            } else {
                customFunctionInput.style.display = "none";
                customFunctionLabel.style.display = "none";
            }
        });

        customFunctionInput.addEventListener("change", function () {
            // Validate the custom function
            try {
                let testFunc = new Function('x', 'return ' + this.value);
                testFunc(0); // Try evaluating at x=0
            } catch (e) {
                alert("Invalid function expression. Please check your syntax.");
                this.value = "Math.sin(x)"; // Reset to a valid expression
            }
        });

        hiddenSizeInput.addEventListener("change", function () {
            const size = parseInt(this.value);
            if (size > 0) {
                nn.setHiddenSize(size);
            } else {
                this.value = "1";
                nn.setHiddenSize(1);
            }
        });

        learningRateInput.addEventListener("change", function () {
            const rate = parseFloat(this.value);
            if (rate > 0) {
                nn.setLearningRate(rate);
            } else {
                this.value = "0.01";
                nn.setLearningRate(0.01);
            }
        });

        batchSizeInput.addEventListener("change", function () {
            const size = parseInt(this.value);
            if (size > 0) {
                batchSize = size;
            } else {
                this.value = "100";
                batchSize = 100;
            }
        });

        resetButton.addEventListener("click", function () {
            nn.initializeWeights();
        });

        pauseButton.addEventListener("click", function () {
            isTraining = !isTraining;
            this.textContent = isTraining ? "Pause Training" : "Resume Training";
        });

        // Animation loop: perform multiple training steps per frame, update drawing, stats, and export code
        function animate() {
            for (let i = 0; i < batchSize; i++) {
                trainStep();
            }
            draw();
            updateStats();
            updateExport();
            requestAnimationFrame(animate);
        }

        // Start the animation loop
        animate();
    </script>
</body>

</html>